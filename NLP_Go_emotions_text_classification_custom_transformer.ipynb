{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqSMeh_gSD5b"
      },
      "source": [
        "***Load and Explore Dataset:***\n",
        "\n",
        "Loads the GoEmotions dataset, a multi-label emotion classification dataset consisting of text samples and associated emotions. Performs initial data exploration to understand dimensions, view sample records, and identify any missing values or dominant emotion categories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-04-06T22:28:42.819368Z",
          "iopub.status.busy": "2025-04-06T22:28:42.819007Z",
          "iopub.status.idle": "2025-04-06T22:28:44.436777Z",
          "shell.execute_reply": "2025-04-06T22:28:44.436004Z",
          "shell.execute_reply.started": "2025-04-06T22:28:42.819343Z"
        },
        "id": "XY6oMRkxR4NQ",
        "outputId": "8b3b2ed9-8bbd-4e80-e214-e1591b8e221c",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of dataset: (211225, 31)\n",
            "\n",
            "Column Names: ['id', 'text', 'example_very_unclear', 'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
            "\n",
            "Sample data:\n",
            "        id                                               text  \\\n",
            "0  eew5j0j                                    That game hurt.   \n",
            "1  eemcysk   >sexuality shouldnâ€™t be a grouping category I...   \n",
            "2  ed2mah1     You do right, if you don't care then fuck 'em!   \n",
            "3  eeibobj                                 Man I love reddit.   \n",
            "4  eda6yn6  [NAME] was nowhere near them, he was by the Fa...   \n",
            "\n",
            "   example_very_unclear  admiration  amusement  anger  annoyance  approval  \\\n",
            "0                 False           0          0      0          0         0   \n",
            "1                  True           0          0      0          0         0   \n",
            "2                 False           0          0      0          0         0   \n",
            "3                 False           0          0      0          0         0   \n",
            "4                 False           0          0      0          0         0   \n",
            "\n",
            "   caring  confusion  ...  love  nervousness  optimism  pride  realization  \\\n",
            "0       0          0  ...     0            0         0      0            0   \n",
            "1       0          0  ...     0            0         0      0            0   \n",
            "2       0          0  ...     0            0         0      0            0   \n",
            "3       0          0  ...     1            0         0      0            0   \n",
            "4       0          0  ...     0            0         0      0            0   \n",
            "\n",
            "   relief  remorse  sadness  surprise  neutral  \n",
            "0       0        0        1         0        0  \n",
            "1       0        0        0         0        0  \n",
            "2       0        0        0         0        1  \n",
            "3       0        0        0         0        0  \n",
            "4       0        0        0         0        1  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "Missing values per column:\n",
            "id                      0\n",
            "text                    0\n",
            "example_very_unclear    0\n",
            "admiration              0\n",
            "amusement               0\n",
            "anger                   0\n",
            "annoyance               0\n",
            "approval                0\n",
            "caring                  0\n",
            "confusion               0\n",
            "curiosity               0\n",
            "desire                  0\n",
            "disappointment          0\n",
            "disapproval             0\n",
            "disgust                 0\n",
            "embarrassment           0\n",
            "excitement              0\n",
            "fear                    0\n",
            "gratitude               0\n",
            "grief                   0\n",
            "joy                     0\n",
            "love                    0\n",
            "nervousness             0\n",
            "optimism                0\n",
            "pride                   0\n",
            "realization             0\n",
            "relief                  0\n",
            "remorse                 0\n",
            "sadness                 0\n",
            "surprise                0\n",
            "neutral                 0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = \"/kaggle/input/go-emotions/go_emotions_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Show basic info about the dataset\n",
        "print(\"Shape of dataset:\", df.shape)\n",
        "print(\"\\nColumn Names:\", df.columns.tolist())\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(\"\\nSample data:\")\n",
        "print(df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Optional: Check unique categories (assuming 'categories' column exists)\n",
        "if 'categories' in df.columns:\n",
        "    print(\"\\nUnique primary categories (top 10):\")\n",
        "    print(df['categories'].value_counts().head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j92NToZqSWnT"
      },
      "source": [
        " ***Inspect Data Columns:***\n",
        "\n",
        " Displays all column names in the dataset to confirm availability of essential fields like text, labels, and optional metadata. This helps guide preprocessing and modeling decisions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T22:32:38.938959Z",
          "iopub.status.busy": "2025-04-06T22:32:38.938513Z",
          "iopub.status.idle": "2025-04-06T22:32:38.943497Z",
          "shell.execute_reply": "2025-04-06T22:32:38.942461Z",
          "shell.execute_reply.started": "2025-04-06T22:32:38.938917Z"
        },
        "id": "2VZjW7r6R4NS",
        "outputId": "1b0a1534-1adc-4eee-f623-7a9ce89b474f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['id', 'text', 'example_very_unclear', 'admiration', 'amusement',\n",
            "       'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity',\n",
            "       'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment',\n",
            "       'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love',\n",
            "       'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse',\n",
            "       'sadness', 'surprise', 'neutral'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df.columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sip2e3T9Sau0"
      },
      "source": [
        "***Import Core Libraries:***\n",
        "\n",
        "Imports required libraries for data manipulation (NumPy, Pandas), visualization (Matplotlib, Seaborn), deep learning (TensorFlow, Keras), and evaluation (Scikit-learn). These tools form the foundation for preprocessing, model building, and performance tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T22:39:31.393783Z",
          "iopub.status.busy": "2025-04-06T22:39:31.393431Z",
          "iopub.status.idle": "2025-04-06T22:39:34.416131Z",
          "shell.execute_reply": "2025-04-06T22:39:34.415431Z",
          "shell.execute_reply.started": "2025-04-06T22:39:31.393761Z"
        },
        "id": "5JBdVjQMR4NS",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "import time\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_V9Zz0hSmza"
      },
      "source": [
        "***Import Modeling Utilities:***\n",
        "\n",
        "Loads specific TensorFlow/Keras layers and metrics used for building a custom deep learning model. Also includes roc_auc_score and f1_score to evaluate multi-label classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T23:16:13.378080Z",
          "iopub.status.busy": "2025-04-06T23:16:13.377663Z",
          "iopub.status.idle": "2025-04-06T23:16:13.383747Z",
          "shell.execute_reply": "2025-04-06T23:16:13.382753Z",
          "shell.execute_reply.started": "2025-04-06T23:16:13.378048Z"
        },
        "id": "YQbOo7pyR4NS",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling1D, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRaqdDntSjK_"
      },
      "source": [
        "***Custom Metrics Callback:***\n",
        "\n",
        "Implements a custom Keras callback to monitor performance on the validation set during training. It evaluates multiple threshold values for converting probabilities into binary predictions and selects the best threshold based on macro F1-score â€” critical for multi-label settings like emotion classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T23:17:06.578004Z",
          "iopub.status.busy": "2025-04-06T23:17:06.577633Z",
          "iopub.status.idle": "2025-04-06T23:17:06.584822Z",
          "shell.execute_reply": "2025-04-06T23:17:06.583838Z",
          "shell.execute_reply.started": "2025-04-06T23:17:06.577979Z"
        },
        "id": "nNWHHhXiR4NS",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# Custom Metrics Callback\n",
        "# ================================\n",
        "class MetricsCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, X_val, y_val, thresholds=np.arange(0.1, 0.6, 0.1)):\n",
        "        super().__init__()\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.thresholds = thresholds\n",
        "        self.best_threshold = 0.5\n",
        "        self.best_macro_f1 = 0.0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        y_pred_probs = self.model.predict(self.X_val, verbose=0)\n",
        "        for threshold in self.thresholds:\n",
        "            y_pred_bin = (y_pred_probs >= threshold).astype(int)\n",
        "            macro_f1 = f1_score(self.y_val, y_pred_bin, average='macro', zero_division=0)\n",
        "            if macro_f1 > self.best_macro_f1:\n",
        "                self.best_macro_f1 = macro_f1\n",
        "                self.best_threshold = threshold\n",
        "\n",
        "        try:\n",
        "            micro_auc = roc_auc_score(self.y_val, y_pred_probs, average='micro')\n",
        "        except ValueError:\n",
        "            micro_auc = float('nan')\n",
        "\n",
        "        print(f\"ğŸ”¹ [Epoch {epoch+1}] Best Macro F1: {self.best_macro_f1:.4f} at threshold={self.best_threshold:.2f}\")\n",
        "        print(f\"ğŸ”¹ [Epoch {epoch+1}] Micro AUC: {micro_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AskHNpYaS0Su"
      },
      "source": [
        "***Load & Prepare Multi-label Emotion Data:***\n",
        "\n",
        "We load the GoEmotions dataset and prepare it for training by extracting the input texts and corresponding multi-label emotion annotations. The dataset is split into training, validation, and test sets using an 80/10/10 ratio. This setup ensures that the model is trained, tuned, and evaluated fairly without data leakage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T22:39:47.238855Z",
          "iopub.status.busy": "2025-04-06T22:39:47.238228Z",
          "iopub.status.idle": "2025-04-06T22:39:48.077391Z",
          "shell.execute_reply": "2025-04-06T22:39:48.076687Z",
          "shell.execute_reply.started": "2025-04-06T22:39:47.238826Z"
        },
        "id": "wn-VTVSFR4NT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# Load and Preprocess GoEmotions Dataset\n",
        "# =========================================\n",
        "file_path = \"/kaggle/input/go-emotions/go_emotions_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Extract texts and multi-labels\n",
        "texts = df['text'].tolist()\n",
        "label_columns = df.columns[3:]  # skip id, text, example_very_unclear\n",
        "labels = df[label_columns].values\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGqTB9SbTTTm"
      },
      "source": [
        "***Tokenization & Sequence Padding***\n",
        "\n",
        "Texts are converted into sequences of integers using a Tokenizer limited to 20,000 most frequent words. Each sequence is padded to a fixed length of 100 tokens to ensure consistent input size for the model. This step prepares raw text for input into the embedding and transformer layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T22:39:58.098288Z",
          "iopub.status.busy": "2025-04-06T22:39:58.097973Z",
          "iopub.status.idle": "2025-04-06T22:40:04.423319Z",
          "shell.execute_reply": "2025-04-06T22:40:04.422392Z",
          "shell.execute_reply.started": "2025-04-06T22:39:58.098267Z"
        },
        "id": "vZPhi7erR4NT",
        "outputId": "6c79865f-81c2-4af5-8d7d-1bdb9d8cbbc0",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Tokenizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 168980/168980 [00:02<00:00, 70556.45it/s]\n",
            "Tokenizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21122/21122 [00:00<00:00, 78746.49it/s]\n",
            "Tokenizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21123/21123 [00:00<00:00, 78295.91it/s]\n"
          ]
        }
      ],
      "source": [
        "# =========================================\n",
        "# Tokenization & Padding\n",
        "# =========================================\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words=20000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "maxlen = 100\n",
        "\n",
        "def encode_pad(texts):\n",
        "    seqs = [tokenizer.texts_to_sequences([t])[0] for t in tqdm(texts, desc=\"Tokenizing\")]\n",
        "    return keras.preprocessing.sequence.pad_sequences(seqs, maxlen=maxlen)\n",
        "\n",
        "X_train_pad = encode_pad(X_train)\n",
        "X_val_pad = encode_pad(X_val)\n",
        "X_test_pad = encode_pad(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzS1lh0kTgL8"
      },
      "source": [
        "***Define Transformer Block***\n",
        "\n",
        "We define a custom Transformer encoder block using multi-head self-attention, followed by feed-forward layers and residual connections. This layer captures contextual relationships in the input sequence and is key to learning meaningful representations for each token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T23:19:43.503074Z",
          "iopub.status.busy": "2025-04-06T23:19:43.502575Z",
          "iopub.status.idle": "2025-04-06T23:19:43.509380Z",
          "shell.execute_reply": "2025-04-06T23:19:43.508337Z",
          "shell.execute_reply.started": "2025-04-06T23:19:43.503033Z"
        },
        "id": "_JCfbw-fR4NT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential([\n",
        "            Dense(ff_dim, activation='relu'),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=False, mask=None):\n",
        "        attn_output = self.att(inputs, inputs, attention_mask=mask)\n",
        "        out1 = self.norm1(inputs + self.dropout1(attn_output, training=training))\n",
        "        ffn_output = self.ffn(out1)\n",
        "        return self.norm2(out1 + self.dropout2(ffn_output, training=training))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHCO-XZQTs8C"
      },
      "source": [
        "***Token + Positional Embedding Layer***\n",
        "\n",
        "Since transformers have no inherent sense of order, we embed both tokens and their positions in the input. This custom layer ensures the model can learn not only what each word means but also where it appears in the sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T23:19:46.018085Z",
          "iopub.status.busy": "2025-04-06T23:19:46.017586Z",
          "iopub.status.idle": "2025-04-06T23:19:46.023432Z",
          "shell.execute_reply": "2025-04-06T23:19:46.022565Z",
          "shell.execute_reply.started": "2025-04-06T23:19:46.018045Z"
        },
        "id": "OxDj_yv2R4NT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class TokenAndPositionEmbedding(Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.token_emb = Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        positions = tf.range(start=0, limit=tf.shape(x)[1], delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rl1-4gPT2M9"
      },
      "source": [
        "***Build and Compile the Transformer Model***\n",
        "\n",
        "This block constructs the final Transformer model using stacked self-attention layers, pooling, and dense layers. It outputs multi-label predictions using a sigmoid activation across 28 emotion classes. The model is compiled with binary cross-entropy loss and AUC, precision, and recall metrics â€” all important for multi-label classification evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T23:20:08.067788Z",
          "iopub.status.busy": "2025-04-06T23:20:08.067454Z",
          "iopub.status.idle": "2025-04-06T23:20:08.938539Z",
          "shell.execute_reply": "2025-04-06T23:20:08.937840Z",
          "shell.execute_reply.started": "2025-04-06T23:20:08.067764Z"
        },
        "id": "N_OGlvfmR4NT",
        "outputId": "f81eaea7-8ec0-42d0-d39c-ed6c8885b8e4",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_14\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)              </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">        Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to           </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_10            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ token_and_position_embedâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,572,800</span> â”‚ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbeddiâ€¦</span> â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ transformer_block_8       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">330,240</span> â”‚ token_and_position_emâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)        â”‚                        â”‚                â”‚ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ transformer_block_9       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">330,240</span> â”‚ transformer_block_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)        â”‚                        â”‚                â”‚ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ transformer_block_10      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">330,240</span> â”‚ transformer_block_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)        â”‚                        â”‚                â”‚ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ transformer_block_11      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">330,240</span> â”‚ transformer_block_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)        â”‚                        â”‚                â”‚ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling1dâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ transformer_block_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> â”‚ dropout_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,612</span> â”‚ dropout_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_10            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            â”‚              \u001b[38;5;34m0\u001b[0m â”‚ -                      â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ token_and_position_embedâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚      \u001b[38;5;34m2,572,800\u001b[0m â”‚ input_layer_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mTokenAndPositionEmbeddiâ€¦\u001b[0m â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)      â”‚              \u001b[38;5;34m0\u001b[0m â”‚ input_layer_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ transformer_block_8       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m330,240\u001b[0m â”‚ token_and_position_emâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mTransformerBlock\u001b[0m)        â”‚                        â”‚                â”‚ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ transformer_block_9       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m330,240\u001b[0m â”‚ transformer_block_8[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mTransformerBlock\u001b[0m)        â”‚                        â”‚                â”‚ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ transformer_block_10      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m330,240\u001b[0m â”‚ transformer_block_9[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mTransformerBlock\u001b[0m)        â”‚                        â”‚                â”‚ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ transformer_block_11      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m330,240\u001b[0m â”‚ transformer_block_10[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mTransformerBlock\u001b[0m)        â”‚                        â”‚                â”‚ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling1dâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚              \u001b[38;5;34m0\u001b[0m â”‚ transformer_block_11[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_40 (\u001b[38;5;33mDropout\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚              \u001b[38;5;34m0\u001b[0m â”‚ global_average_poolinâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_28 (\u001b[38;5;33mDense\u001b[0m)          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m16,512\u001b[0m â”‚ dropout_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_41 (\u001b[38;5;33mDropout\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚              \u001b[38;5;34m0\u001b[0m â”‚ dense_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_29 (\u001b[38;5;33mDense\u001b[0m)          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             â”‚          \u001b[38;5;34m3,612\u001b[0m â”‚ dropout_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,913,884</span> (14.93 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,913,884\u001b[0m (14.93 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,913,884</span> (14.93 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,913,884\u001b[0m (14.93 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ================================\n",
        "vocab_size = 20000\n",
        "embed_dim = 128\n",
        "num_heads = 4\n",
        "ff_dim = 256\n",
        "num_classes = y_train.shape[1]  # 28 emotions\n",
        "\n",
        "inputs = Input(shape=(maxlen,))\n",
        "embedding = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)(inputs)\n",
        "mask = Lambda(lambda x: tf.cast(tf.not_equal(x, 0), tf.int32)[:, tf.newaxis, tf.newaxis, :])(inputs)\n",
        "\n",
        "x = embedding\n",
        "for _ in range(4):\n",
        "    x = TransformerBlock(embed_dim, num_heads, ff_dim)(x, mask=mask)\n",
        "\n",
        "x = GlobalAveragePooling1D()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(num_classes, activation='sigmoid')(x)  # sigmoid for multi-label\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-3),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[\n",
        "        AUC(name='auc', multi_label=True),\n",
        "        Precision(name='precision'),\n",
        "        Recall(name='recall')\n",
        "    ])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BGqVHFkUE7g"
      },
      "source": [
        "***Define and Compile the Model***\n",
        "\n",
        "This cell defines the deep learning model architecture for multi-label emotion classification. It likely uses an embedding layer (like BERT or pretrained embeddings) followed by dense layers with a sigmoid activation to handle multilabel outputs. The model is compiled with a binary cross-entropy loss and appropriate metrics for multilabel classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge-6l40EUpqy"
      },
      "source": [
        "***Train the Model with Custom Callback***\n",
        "\n",
        "We train the model using the training dataset with validation monitoring and multiple callbacks:\n",
        "\n",
        "EarlyStopping halts training if validation performance stops improving.\n",
        "\n",
        "ModelCheckpoint saves the best model based on validation loss.\n",
        "\n",
        "MetricsCallback is a custom callback that dynamically tracks the best F1 score and threshold. The model is trained for up to 20 epochs with a batch size of 64, and the total training time is logged."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T23:20:14.737774Z",
          "iopub.status.busy": "2025-04-06T23:20:14.737455Z",
          "iopub.status.idle": "2025-04-06T23:32:23.097214Z",
          "shell.execute_reply": "2025-04-06T23:32:23.096354Z",
          "shell.execute_reply.started": "2025-04-06T23:20:14.737750Z"
        },
        "id": "B4SI-jVmR4NT",
        "outputId": "56a47682-1e67-41e0-deac-66dbce8f548f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "ğŸ”¹ [Epoch 1] Best Macro F1: 0.1066 at threshold=0.10\n",
            "ğŸ”¹ [Epoch 1] Micro AUC: 0.8152\n",
            "2641/2641 - 107s - 41ms/step - auc: 0.5899 - loss: 0.1551 - precision: 0.4963 - recall: 0.0281 - val_auc: 0.6937 - val_loss: 0.1397 - val_precision: 0.7310 - val_recall: 0.0638\n",
            "Epoch 2/20\n",
            "ğŸ”¹ [Epoch 2] Best Macro F1: 0.1958 at threshold=0.10\n",
            "ğŸ”¹ [Epoch 2] Micro AUC: 0.8469\n",
            "2641/2641 - 68s - 26ms/step - auc: 0.7109 - loss: 0.1387 - precision: 0.6389 - recall: 0.0946 - val_auc: 0.7590 - val_loss: 0.1326 - val_precision: 0.6372 - val_recall: 0.1142\n",
            "Epoch 3/20\n",
            "ğŸ”¹ [Epoch 3] Best Macro F1: 0.1974 at threshold=0.10\n",
            "ğŸ”¹ [Epoch 3] Micro AUC: 0.8480\n",
            "2641/2641 - 69s - 26ms/step - auc: 0.7481 - loss: 0.1348 - precision: 0.6352 - recall: 0.1147 - val_auc: 0.7588 - val_loss: 0.1323 - val_precision: 0.6296 - val_recall: 0.1196\n",
            "Epoch 4/20\n",
            "ğŸ”¹ [Epoch 4] Best Macro F1: 0.2133 at threshold=0.10\n",
            "ğŸ”¹ [Epoch 4] Micro AUC: 0.8510\n",
            "2641/2641 - 68s - 26ms/step - auc: 0.7665 - loss: 0.1314 - precision: 0.6485 - recall: 0.1372 - val_auc: 0.7607 - val_loss: 0.1317 - val_precision: 0.5997 - val_recall: 0.1455\n",
            "Epoch 5/20\n",
            "ğŸ”¹ [Epoch 5] Best Macro F1: 0.2268 at threshold=0.10\n",
            "ğŸ”¹ [Epoch 5] Micro AUC: 0.8513\n",
            "2641/2641 - 68s - 26ms/step - auc: 0.7733 - loss: 0.1304 - precision: 0.6552 - recall: 0.1403 - val_auc: 0.7642 - val_loss: 0.1313 - val_precision: 0.6322 - val_recall: 0.1345\n",
            "Epoch 6/20\n",
            "ğŸ”¹ [Epoch 6] Best Macro F1: 0.2304 at threshold=0.10\n",
            "ğŸ”¹ [Epoch 6] Micro AUC: 0.8489\n",
            "2641/2641 - 68s - 26ms/step - auc: 0.7757 - loss: 0.1300 - precision: 0.6574 - recall: 0.1414 - val_auc: 0.7563 - val_loss: 0.1329 - val_precision: 0.5791 - val_recall: 0.1494\n",
            "Epoch 7/20\n",
            "ğŸ”¹ [Epoch 7] Best Macro F1: 0.2350 at threshold=0.10\n",
            "ğŸ”¹ [Epoch 7] Micro AUC: 0.8529\n",
            "2641/2641 - 68s - 26ms/step - auc: 0.7829 - loss: 0.1285 - precision: 0.6674 - recall: 0.1498 - val_auc: 0.7611 - val_loss: 0.1309 - val_precision: 0.6249 - val_recall: 0.1424\n",
            "Epoch 8/20\n",
            "ğŸ”¹ [Epoch 8] Best Macro F1: 0.2391 at threshold=0.10\n",
            "ğŸ”¹ [Epoch 8] Micro AUC: 0.8490\n",
            "2641/2641 - 68s - 26ms/step - auc: 0.7806 - loss: 0.1289 - precision: 0.6680 - recall: 0.1461 - val_auc: 0.7581 - val_loss: 0.1320 - val_precision: 0.6164 - val_recall: 0.1415\n",
            "Epoch 9/20\n",
            "ğŸ”¹ [Epoch 9] Best Macro F1: 0.2391 at threshold=0.10\n",
            "ğŸ”¹ [Epoch 9] Micro AUC: 0.8466\n",
            "2641/2641 - 68s - 26ms/step - auc: 0.7815 - loss: 0.1286 - precision: 0.6699 - recall: 0.1493 - val_auc: 0.7528 - val_loss: 0.1330 - val_precision: 0.6144 - val_recall: 0.1373\n",
            "Epoch 10/20\n",
            "ğŸ”¹ [Epoch 10] Best Macro F1: 0.2391 at threshold=0.10\n",
            "ğŸ”¹ [Epoch 10] Micro AUC: 0.8495\n",
            "2641/2641 - 68s - 26ms/step - auc: 0.7837 - loss: 0.1281 - precision: 0.6690 - recall: 0.1527 - val_auc: 0.7598 - val_loss: 0.1322 - val_precision: 0.5906 - val_recall: 0.1600\n",
            "âœ… Training completed in 722.98 seconds\n",
            "\n",
            "ğŸ Best threshold from training: 0.10\n",
            "\u001b[1m331/331\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step\n",
            "ğŸ¯ Final Macro F1-score on Test: 0.2382\n",
            "ğŸ¯ Final Micro AUC-score on Test: 0.8553\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# ================================\n",
        "# Define and Compile Model\n",
        "\n",
        "\n",
        "\n",
        "# ================================\n",
        "# Train Model with Custom Callback\n",
        "# ================================\n",
        "metrics_callback = MetricsCallback(X_val_pad, y_val)\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ModelCheckpoint('best_goemotions_model.keras', save_best_only=True),\n",
        "    metrics_callback\n",
        "]\n",
        "\n",
        "start_time = time.time()\n",
        "history = model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    verbose=2,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "training_time = time.time() - start_time\n",
        "print(\"âœ… Training completed in {:.2f} seconds\".format(training_time))\n",
        "\n",
        "# ================================\n",
        "# Final Test Evaluation\n",
        "# ================================\n",
        "best_threshold = metrics_callback.best_threshold\n",
        "print(f\"\\nğŸ Best threshold from training: {best_threshold:.2f}\")\n",
        "\n",
        "y_pred_probs = model.predict(X_test_pad, batch_size=64)\n",
        "y_pred_bin = (y_pred_probs >= best_threshold).astype(int)\n",
        "\n",
        "# Final metrics\n",
        "macro_f1 = f1_score(y_test, y_pred_bin, average='macro', zero_division=0)\n",
        "try:\n",
        "    micro_auc = roc_auc_score(y_test, y_pred_probs, average='micro')\n",
        "except ValueError:\n",
        "    micro_auc = float('nan')\n",
        "\n",
        "print(f\"ğŸ¯ Final Macro F1-score on Test: {macro_f1:.4f}\")\n",
        "print(f\"ğŸ¯ Final Micro AUC-score on Test: {micro_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T23:40:26.348135Z",
          "iopub.status.busy": "2025-04-06T23:40:26.347760Z",
          "iopub.status.idle": "2025-04-06T23:40:26.352155Z",
          "shell.execute_reply": "2025-04-06T23:40:26.351145Z",
          "shell.execute_reply.started": "2025-04-06T23:40:26.348112Z"
        },
        "id": "vkzSzWEqR4NU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Sample test sentences (you can replace or load from CSV)\n",
        "new_texts = [\n",
        "    \"I'm extremely happy and proud of what I achieved!\",\n",
        "    \"This is the worst thing ever. I'm so mad.\",\n",
        "    \"I'm feeling so lost and unsure about everything.\",\n",
        "    \"Wow, what a surprise! Totally unexpected.\",\n",
        "    \"I really appreciate your kindness.\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T23:40:38.707511Z",
          "iopub.status.busy": "2025-04-06T23:40:38.707212Z",
          "iopub.status.idle": "2025-04-06T23:40:38.714969Z",
          "shell.execute_reply": "2025-04-06T23:40:38.714103Z",
          "shell.execute_reply.started": "2025-04-06T23:40:38.707490Z"
        },
        "id": "gHUWlFwGR4NU",
        "outputId": "795d85b3-03df-47f8-b755-88ba0e2827a2",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Tokenizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 18493.40it/s]\n"
          ]
        }
      ],
      "source": [
        "# Use your defined function\n",
        "X_new_pad = encode_pad(new_texts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNp0plqqU8R6"
      },
      "source": [
        "***Evaluate Model on Test Set***\n",
        "\n",
        "After training, we evaluate the model on the test set using the best threshold learned during validation. We compute:\n",
        "\n",
        "Macro F1-score: Averages F1 across all emotion classes equally.\n",
        "\n",
        "Micro AUC: Measures the area under the ROC curve across all labels. This provides a robust understanding of the modelâ€™s multilabel classification performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T23:40:52.427471Z",
          "iopub.status.busy": "2025-04-06T23:40:52.427131Z",
          "iopub.status.idle": "2025-04-06T23:40:54.339409Z",
          "shell.execute_reply": "2025-04-06T23:40:54.338726Z",
          "shell.execute_reply.started": "2025-04-06T23:40:52.427442Z"
        },
        "id": "LbH7wQl0R4NU",
        "outputId": "e2c9c584-f54f-4fd3-c381-41b47ca0cb62",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
          ]
        }
      ],
      "source": [
        "# Predict probabilities\n",
        "y_pred_probs_new = model.predict(X_new_pad, batch_size=64)\n",
        "\n",
        "# Apply threshold from training\n",
        "y_pred_bin_new = (y_pred_probs_new >= best_threshold).astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK-QZJLJVBHn"
      },
      "source": [
        "***Make Predictions on New Text Inputs***\n",
        "\n",
        "We now apply the trained model to new, unseen text examples. Probabilities are predicted for each emotion label, and then binarized using the best threshold. This step simulates real-world inference where user-generated text is input and emotions are predicted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T23:41:10.352706Z",
          "iopub.status.busy": "2025-04-06T23:41:10.352368Z",
          "iopub.status.idle": "2025-04-06T23:41:10.360632Z",
          "shell.execute_reply": "2025-04-06T23:41:10.359822Z",
          "shell.execute_reply.started": "2025-04-06T23:41:10.352680Z"
        },
        "id": "gvRmzqCxR4NU",
        "outputId": "ec4783c6-b2e1-4913-bd2a-e75d8899e12e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# GoEmotions labels\n",
        "labels = [\n",
        "    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\",\n",
        "    \"confusion\", \"curiosity\", \"desire\", \"disappointment\", \"disapproval\",\n",
        "    \"disgust\", \"embarrassment\", \"excitement\", \"fear\", \"gratitude\", \"grief\",\n",
        "    \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\", \"relief\",\n",
        "    \"remorse\", \"sadness\", \"surprise\", \"neutral\"\n",
        "]\n",
        "\n",
        "# Format predictions\n",
        "for text, bin_preds in zip(new_texts, y_pred_bin_new):\n",
        "    predicted_emotions = [label for label, val in zip(labels, bin_preds) if val == 1]\n",
        "    print(f\"\\nğŸ“ Text: {text}\")\n",
        "    print(f\"ğŸ” Predicted Emotions: {predicted_emotions if predicted_emotions else ['None']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee2GuuoBVLlg"
      },
      "source": [
        "***Display Final Cleaned Predictions***\n",
        "\n",
        "The cleaned emotion predictions are displayed for each input sentence. This final step showcases how the model works in a practical setting, highlighting its ability to capture complex emotional nuances beyond simple positive/negative/neutral sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T23:44:12.353521Z",
          "iopub.status.busy": "2025-04-06T23:44:12.353163Z",
          "iopub.status.idle": "2025-04-06T23:44:12.361111Z",
          "shell.execute_reply": "2025-04-06T23:44:12.360288Z",
          "shell.execute_reply.started": "2025-04-06T23:44:12.353498Z"
        },
        "id": "fpPDPiBTR4NU",
        "outputId": "43cd51f4-7d28-4acf-e543-0ef276986139",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“ Text: I'm extremely happy and proud of what I achieved!\n",
            "ğŸ¯ Final Emotions: ['admiration', 'joy']\n",
            "\n",
            "ğŸ“ Text: This is the worst thing ever. I'm so mad.\n",
            "ğŸ¯ Final Emotions: ['anger', 'annoyance', 'disgust']\n",
            "\n",
            "ğŸ“ Text: I'm feeling so lost and unsure about everything.\n",
            "ğŸ¯ Final Emotions: ['disapproval']\n",
            "\n",
            "ğŸ“ Text: Wow, what a surprise! Totally unexpected.\n",
            "ğŸ¯ Final Emotions: ['approval']\n",
            "\n",
            "ğŸ“ Text: I really appreciate your kindness.\n",
            "ğŸ¯ Final Emotions: ['admiration', 'gratitude', 'joy']\n"
          ]
        }
      ],
      "source": [
        "# If any non-neutral emotion is predicted, remove 'neutral'\n",
        "def clean_emotions(preds, labels):\n",
        "    cleaned = []\n",
        "    for pred in preds:\n",
        "        emotions = [label for i, label in enumerate(labels) if pred[i] == 1]\n",
        "        if 'neutral' in emotions and len(emotions) > 1:\n",
        "            emotions.remove('neutral')\n",
        "        cleaned.append(emotions)\n",
        "    return cleaned\n",
        "\n",
        "# Apply to your predictions\n",
        "cleaned_preds = clean_emotions(y_pred_bin_new, labels)\n",
        "\n",
        "# Display\n",
        "for text, emotions in zip(new_texts, cleaned_preds):\n",
        "    print(f\"\\nğŸ“ Text: {text}\")\n",
        "    print(f\"ğŸ¯ Final Emotions: {emotions if emotions else ['None']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Y0FlDhSR4NU",
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 7067971,
          "sourceId": 11301875,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 7068247,
          "sourceId": 11302232,
          "sourceType": "datasetVersion"
        },
        {
          "sourceId": 37881041,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 30919,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
